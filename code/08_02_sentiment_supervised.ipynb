{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary depencencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T08:50:23.609566700Z",
     "start_time": "2023-11-30T08:49:39.094700600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yhutter\\AppData\\Local\\Temp\\ipykernel_27220\\483943083.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "C:\\Users\\yhutter\\GitRepos\\fhgr-ta\\code\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\yhutter\\GitRepos\\fhgr-ta\\code\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\yhutter\\GitRepos\\fhgr-ta\\code\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import text_normalizer as tn\n",
    "import model_evaluation_utils_hr as meu\n",
    "import nltk\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:37:18.920957900Z",
     "start_time": "2023-11-30T08:50:27.944262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yhutter\\GitRepos\\fhgr-ta\\code\\text_normalizer.py:20: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:20\u001b[0m\n",
      "File \u001b[1;32m~\\GitRepos\\fhgr-ta\\code\\text_normalizer.py:126\u001b[0m, in \u001b[0;36mnormalize_corpus\u001b[1;34m(corpus, html_stripping, contraction_expansion, accented_char_removal, text_lower_case, text_stemming, text_lemmatization, special_char_removal, remove_digits, stopword_removal, stopwords)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# lemmatize text\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_lemmatization:\n\u001b[1;32m--> 126\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mlemmatize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# stem text\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_stemming \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m text_lemmatization:\n",
      "File \u001b[1;32m~\\GitRepos\\fhgr-ta\\code\\text_normalizer.py:41\u001b[0m, in \u001b[0;36mlemmatize_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize_text\u001b[39m(text):\n\u001b[1;32m---> 41\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([word\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-PRON-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m word\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text])\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[1;32m~\\GitRepos\\fhgr-ta\\code\\venv\\Lib\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = pd.read_csv('./movie_reviews.zip', compression='zip')\n",
    "\n",
    "# take a peek at the data\n",
    "print(dataset.head())\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# build train and test datasets\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]\n",
    "\n",
    "# normalize datasets\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('but')\n",
    "stop_words.remove('not')\n",
    "\n",
    "norm_train_reviews = tn.normalize_corpus(train_reviews, stopwords=stop_words)\n",
    "norm_test_reviews = tn.normalize_corpus(test_reviews, stopwords=stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Supervised Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "(dauert etwas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:38:01.930018Z",
     "start_time": "2023-11-30T09:37:18.923247100Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# build BOW features on train reviews\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
    "# build TFIDF features on train reviews\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),\n",
    "                     sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(norm_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:39:08.544207500Z",
     "start_time": "2023-11-30T09:38:59.502274600Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform test reviews into features\n",
    "cv_test_features = cv.transform(norm_test_reviews)\n",
    "tv_test_features = tv.transform(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:39:10.001118Z",
     "start_time": "2023-11-30T09:39:09.954384700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (35000, 2091982)  Test features shape: (15000, 2091982)\n",
      "TFIDF model:> Train features shape: (35000, 2091982)  Test features shape: (15000, 2091982)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training, Prediction and Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:39:25.614733800Z",
     "start_time": "2023-11-30T09:39:25.596468800Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
    "svm = SGDClassifier(loss='hinge', max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:40:18.874946700Z",
     "start_time": "2023-11-30T09:39:30.235659600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roelkeheiko\\PycharmProjects\\ta_2023\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.9053\n",
      "Precision: 0.9053\n",
      "Recall: 0.9053\n",
      "F1 Score: 0.9053\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.90      0.91      0.91      7510\n",
      "    negative       0.91      0.90      0.90      7490\n",
      "\n",
      "    accuracy                           0.91     15000\n",
      "   macro avg       0.91      0.91      0.91     15000\n",
      "weighted avg       0.91      0.91      0.91     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6768      722\n",
      "        negative        699     6811\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model on BOW features\n",
    "lr_bow_predictions = meu.train_predict_model(classifier=lr, \n",
    "                                             train_features=cv_train_features, train_labels=train_sentiments,\n",
    "                                             test_features=cv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_predictions,\n",
    "                                      classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:41:36.577022300Z",
     "start_time": "2023-11-30T09:41:08.534743500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8938\n",
      "Precision: 0.8939\n",
      "Recall: 0.8938\n",
      "F1 Score: 0.8938\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.89      0.90      0.89      7510\n",
      "    negative       0.90      0.89      0.89      7490\n",
      "\n",
      "    accuracy                           0.89     15000\n",
      "   macro avg       0.89      0.89      0.89     15000\n",
      "weighted avg       0.89      0.89      0.89     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6649      841\n",
      "        negative        752     6758\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model on TF-IDF features\n",
    "lr_tfidf_predictions = meu.train_predict_model(classifier=lr, \n",
    "                                               train_features=tv_train_features, train_labels=train_sentiments,\n",
    "                                               test_features=tv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_tfidf_predictions,\n",
    "                                      classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Klassifizierung mittels SVM\n",
    "\n",
    "### zuerst BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:41:54.657357Z",
     "start_time": "2023-11-30T09:41:52.248487100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8988\n",
      "Precision: 0.8991\n",
      "Recall: 0.8988\n",
      "F1 Score: 0.8988\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.91      0.89      0.90      7510\n",
      "    negative       0.89      0.91      0.90      7490\n",
      "\n",
      "    accuracy                           0.90     15000\n",
      "   macro avg       0.90      0.90      0.90     15000\n",
      "weighted avg       0.90      0.90      0.90     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6827      663\n",
      "        negative        855     6655\n"
     ]
    }
   ],
   "source": [
    "svm_bow_predictions = meu.train_predict_model(classifier=svm, \n",
    "                                             train_features=cv_train_features, train_labels=train_sentiments,\n",
    "                                             test_features=cv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_bow_predictions,\n",
    "                                      classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### dann auch hier TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:43:42.417481700Z",
     "start_time": "2023-11-30T09:43:40.523007500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8961\n",
      "Precision: 0.8964\n",
      "Recall: 0.8961\n",
      "F1 Score: 0.896\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.88      0.91      0.90      7510\n",
      "    negative       0.91      0.88      0.89      7490\n",
      "\n",
      "    accuracy                           0.90     15000\n",
      "   macro avg       0.90      0.90      0.90     15000\n",
      "weighted avg       0.90      0.90      0.90     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6601      889\n",
      "        negative        670     6840\n"
     ]
    }
   ],
   "source": [
    "svm_tfidf_predictions = meu.train_predict_model(classifier=svm, \n",
    "                                                train_features=tv_train_features, train_labels=train_sentiments,\n",
    "                                                test_features=tv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_tfidf_predictions,\n",
    "                                      classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newer Supervised Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:49:02.386138300Z",
     "start_time": "2023-11-30T09:48:59.211090200Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction class label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:49:25.893348Z",
     "start_time": "2023-11-30T09:49:16.412408500Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "num_classes=2 \n",
    "# tokenize train reviews & encode train labels\n",
    "tokenized_train = [tn.tokenizer.tokenize(text)\n",
    "                   for text in norm_train_reviews]\n",
    "y_tr = le.fit_transform(train_sentiments)\n",
    "y_train = keras.utils.to_categorical(y_tr, num_classes)\n",
    "# tokenize test reviews & encode test labels\n",
    "tokenized_test = [tn.tokenizer.tokenize(text)\n",
    "                   for text in norm_test_reviews]\n",
    "y_ts = le.fit_transform(test_sentiments)\n",
    "y_test = keras.utils.to_categorical(y_ts, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:49:29.981593700Z",
     "start_time": "2023-11-30T09:49:29.943585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment class label map: {'negative': 0, 'positive': 1}\n",
      "Sample test label transformation:\n",
      "----------------------------------- \n",
      "Actual Labels: ['negative' 'positive' 'negative'] \n",
      "Encoded Labels: [0 1 0] \n",
      "One hot encoded Labels:\n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# print class label encoding map and encoded labels\n",
    "print('Sentiment class label map:', dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "print('Sample test label transformation:\\n'+'-'*35,\n",
    "      '\\nActual Labels:', test_sentiments[:3], '\\nEncoded Labels:', y_ts[:3], \n",
    "      '\\nOne hot encoded Labels:\\n', y_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering with word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:54:21.125416900Z",
     "start_time": "2023-11-30T09:52:02.662354600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15min 43s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# build word2vec model\n",
    "w2v_num_features = 512\n",
    "w2v_model = gensim.models.Word2Vec(tokenized_train, vector_size=w2v_num_features, window=150,\n",
    "                                   min_count=10, sample=1e-3, workers=8)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:57:04.505344900Z",
     "start_time": "2023-11-30T09:57:04.461514900Z"
    }
   },
   "outputs": [],
   "source": [
    "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index_to_key)\n",
    "    \n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "        nwords = 0.\n",
    "        \n",
    "        for word in words:\n",
    "            if word in vocabulary: \n",
    "                nwords = nwords + 1.\n",
    "                feature_vector = np.add(feature_vector, model.wv[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "        return feature_vector\n",
    "\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:57:40.683936600Z",
     "start_time": "2023-11-30T09:57:08.621037400Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate averaged word vector features from word2vec model\n",
    "avg_wv_train_features = averaged_word2vec_vectorizer(corpus=tokenized_train, model=w2v_model,\n",
    "                                                     num_features=w2v_num_features)\n",
    "avg_wv_test_features = averaged_word2vec_vectorizer(corpus=tokenized_test, model=w2v_model,\n",
    "                                                    num_features=w2v_num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "zusätzlich GloVe Modell hinzunehmen: vortrainierte Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T10:45:50.594391900Z",
     "start_time": "2023-11-30T10:00:59.529551800Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature engineering with GloVe model\n",
    "#  mit Rückgriff auf spaCy (aus dem Text Normalizer)\n",
    "train_nlp = [tn.nlp(item) for item in norm_train_reviews]\n",
    "train_glove_features = np.array([item.vector for item in train_nlp])\n",
    "\n",
    "test_nlp = [tn.nlp(item) for item in norm_test_reviews]\n",
    "test_glove_features = np.array([item.vector for item in test_nlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T10:45:50.685213300Z",
     "start_time": "2023-11-30T10:45:50.603368200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec model:> Train features shape: (35000, 512)  Test features shape: (15000, 512)\n",
      "GloVe model:> Train features shape: (35000, 96)  Test features shape: (15000, 96)\n"
     ]
    }
   ],
   "source": [
    "print('Word2Vec model:> Train features shape:', avg_wv_train_features.shape, ' Test features shape:', avg_wv_test_features.shape)\n",
    "print('GloVe model:> Train features shape:', train_glove_features.shape, ' Test features shape:', test_glove_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with deep neural networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Deep neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T10:45:50.701902800Z",
     "start_time": "2023-11-30T10:45:50.661022300Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_deepnn_architecture(num_input_features):\n",
    "    dnn_model = Sequential()\n",
    "    dnn_model.add(Dense(512, input_shape=(num_input_features,), kernel_initializer='glorot_uniform'))\n",
    "    dnn_model.add(BatchNormalization())\n",
    "    dnn_model.add(Activation('relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    \n",
    "    dnn_model.add(Dense(512, kernel_initializer='glorot_uniform'))\n",
    "    dnn_model.add(BatchNormalization())\n",
    "    dnn_model.add(Activation('relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    \n",
    "    dnn_model.add(Dense(512, kernel_initializer='glorot_uniform'))\n",
    "    dnn_model.add(BatchNormalization())\n",
    "    dnn_model.add(Activation('relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    \n",
    "    dnn_model.add(Dense(2))\n",
    "    dnn_model.add(Activation('softmax'))\n",
    "\n",
    "    dnn_model.compile(loss='categorical_crossentropy', optimizer='adam',                 \n",
    "                      metrics=['accuracy'])\n",
    "    return dnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T10:45:53.891194500Z",
     "start_time": "2023-11-30T10:45:50.681218400Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_dnn = construct_deepnn_architecture(num_input_features=w2v_num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sample deep architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:29:10.705176900Z",
     "start_time": "2023-11-30T13:29:08.639808700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"362pt\" height=\"1653pt\" viewBox=\"0.00 0.00 271.25 1239.50\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 1235.5)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1235.5 267.25,-1235.5 267.25,4 -4,4\"/>\n",
       "<!-- 2085818295056 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2085818295056</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"19.88,-1183.5 19.88,-1231 243.38,-1231 243.38,-1183.5 19.88,-1183.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.25\" y=\"-1202.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"96.62,-1183.5 96.62,-1231\"/>\n",
       "<text text-anchor=\"middle\" x=\"124.12\" y=\"-1213.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"96.62,-1207.25 151.62,-1207.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"124.12\" y=\"-1189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"151.62,-1183.5 151.62,-1231\"/>\n",
       "<text text-anchor=\"middle\" x=\"197.5\" y=\"-1213.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[(None, 512)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"151.62,-1207.25 243.38,-1207.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"197.5\" y=\"-1189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[(None, 512)]</text>\n",
       "</g>\n",
       "<!-- 2085853290704 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2085853290704</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"37.5,-1099 37.5,-1146.5 225.75,-1146.5 225.75,-1099 37.5,-1099\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-1117.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"88,-1099 88,-1146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-1129.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"88,-1122.75 143,-1122.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-1105.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"143,-1099 143,-1146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.38\" y=\"-1129.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"143,-1122.75 225.75,-1122.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.38\" y=\"-1105.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085818295056&#45;&gt;2085853290704 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2085818295056-&gt;2085853290704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-1183.27C131.62,-1175.56 131.62,-1166.78 131.62,-1158.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-1158.41 131.63,-1148.41 128.13,-1158.41 135.13,-1158.41\"/>\n",
       "</g>\n",
       "<!-- 2085853629712 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2085853629712</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-1014.5 0,-1062 263.25,-1062 263.25,-1014.5 0,-1014.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-1033.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"125.5,-1014.5 125.5,-1062\"/>\n",
       "<text text-anchor=\"middle\" x=\"153\" y=\"-1044.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"125.5,-1038.25 180.5,-1038.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"153\" y=\"-1020.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"180.5,-1014.5 180.5,-1062\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.88\" y=\"-1044.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"180.5,-1038.25 263.25,-1038.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.88\" y=\"-1020.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085853290704&#45;&gt;2085853629712 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2085853290704-&gt;2085853629712</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-1098.77C131.62,-1091.06 131.62,-1082.28 131.62,-1073.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-1073.91 131.63,-1063.91 128.13,-1073.91 135.13,-1073.91\"/>\n",
       "</g>\n",
       "<!-- 2085852942032 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2085852942032</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"26.25,-930 26.25,-977.5 237,-977.5 237,-930 26.25,-930\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-948.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"99.25,-930 99.25,-977.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.75\" y=\"-960.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"99.25,-953.75 154.25,-953.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.75\" y=\"-936.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"154.25,-930 154.25,-977.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.62\" y=\"-960.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"154.25,-953.75 237,-953.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.62\" y=\"-936.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085853629712&#45;&gt;2085852942032 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2085853629712-&gt;2085852942032</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-1014.27C131.62,-1006.56 131.62,-997.78 131.62,-989.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-989.41 131.63,-979.41 128.13,-989.41 135.13,-989.41\"/>\n",
       "</g>\n",
       "<!-- 2085818094416 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2085818094416</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"31.12,-845.5 31.12,-893 232.12,-893 232.12,-845.5 31.12,-845.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-864.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"94.38,-845.5 94.38,-893\"/>\n",
       "<text text-anchor=\"middle\" x=\"121.88\" y=\"-875.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"94.38,-869.25 149.38,-869.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"121.88\" y=\"-851.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"149.38,-845.5 149.38,-893\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.75\" y=\"-875.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"149.38,-869.25 232.12,-869.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.75\" y=\"-851.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085852942032&#45;&gt;2085818094416 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2085852942032-&gt;2085818094416</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-929.77C131.62,-922.06 131.62,-913.28 131.62,-904.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-904.91 131.63,-894.91 128.13,-904.91 135.13,-904.91\"/>\n",
       "</g>\n",
       "<!-- 2085853638608 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2085853638608</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"37.5,-761 37.5,-808.5 225.75,-808.5 225.75,-761 37.5,-761\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-779.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"88,-761 88,-808.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-791.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"88,-784.75 143,-784.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-767.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"143,-761 143,-808.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.38\" y=\"-791.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"143,-784.75 225.75,-784.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.38\" y=\"-767.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085818094416&#45;&gt;2085853638608 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2085818094416-&gt;2085853638608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-845.27C131.62,-837.56 131.62,-828.78 131.62,-820.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-820.41 131.63,-810.41 128.13,-820.41 135.13,-820.41\"/>\n",
       "</g>\n",
       "<!-- 2085876343568 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2085876343568</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-676.5 0,-724 263.25,-724 263.25,-676.5 0,-676.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-695.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"125.5,-676.5 125.5,-724\"/>\n",
       "<text text-anchor=\"middle\" x=\"153\" y=\"-706.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"125.5,-700.25 180.5,-700.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"153\" y=\"-682.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"180.5,-676.5 180.5,-724\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.88\" y=\"-706.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"180.5,-700.25 263.25,-700.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.88\" y=\"-682.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085853638608&#45;&gt;2085876343568 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2085853638608-&gt;2085876343568</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-760.77C131.62,-753.06 131.62,-744.28 131.62,-735.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-735.91 131.63,-725.91 128.13,-735.91 135.13,-735.91\"/>\n",
       "</g>\n",
       "<!-- 2085853084496 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>2085853084496</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"26.25,-592 26.25,-639.5 237,-639.5 237,-592 26.25,-592\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-610.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"99.25,-592 99.25,-639.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.75\" y=\"-622.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"99.25,-615.75 154.25,-615.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.75\" y=\"-598.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"154.25,-592 154.25,-639.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.62\" y=\"-622.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"154.25,-615.75 237,-615.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.62\" y=\"-598.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085876343568&#45;&gt;2085853084496 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2085876343568-&gt;2085853084496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-676.27C131.62,-668.56 131.62,-659.78 131.62,-651.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-651.41 131.63,-641.41 128.13,-651.41 135.13,-651.41\"/>\n",
       "</g>\n",
       "<!-- 2085876490384 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>2085876490384</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"31.12,-507.5 31.12,-555 232.12,-555 232.12,-507.5 31.12,-507.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-526.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"94.38,-507.5 94.38,-555\"/>\n",
       "<text text-anchor=\"middle\" x=\"121.88\" y=\"-537.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"94.38,-531.25 149.38,-531.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"121.88\" y=\"-513.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"149.38,-507.5 149.38,-555\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.75\" y=\"-537.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"149.38,-531.25 232.12,-531.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.75\" y=\"-513.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085853084496&#45;&gt;2085876490384 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2085853084496-&gt;2085876490384</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-591.77C131.62,-584.06 131.62,-575.28 131.62,-566.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-566.91 131.63,-556.91 128.13,-566.91 135.13,-566.91\"/>\n",
       "</g>\n",
       "<!-- 2085853479184 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>2085853479184</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"37.5,-423 37.5,-470.5 225.75,-470.5 225.75,-423 37.5,-423\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-441.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"88,-423 88,-470.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-453.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"88,-446.75 143,-446.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-429.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"143,-423 143,-470.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.38\" y=\"-453.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"143,-446.75 225.75,-446.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.38\" y=\"-429.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085876490384&#45;&gt;2085853479184 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2085876490384-&gt;2085853479184</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-507.27C131.62,-499.56 131.62,-490.78 131.62,-482.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-482.41 131.63,-472.41 128.13,-482.41 135.13,-482.41\"/>\n",
       "</g>\n",
       "<!-- 2085853759504 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>2085853759504</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-338.5 0,-386 263.25,-386 263.25,-338.5 0,-338.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-357.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"125.5,-338.5 125.5,-386\"/>\n",
       "<text text-anchor=\"middle\" x=\"153\" y=\"-368.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"125.5,-362.25 180.5,-362.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"153\" y=\"-344.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"180.5,-338.5 180.5,-386\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.88\" y=\"-368.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"180.5,-362.25 263.25,-362.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.88\" y=\"-344.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085853479184&#45;&gt;2085853759504 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>2085853479184-&gt;2085853759504</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-422.77C131.62,-415.06 131.62,-406.28 131.62,-397.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-397.91 131.63,-387.91 128.13,-397.91 135.13,-397.91\"/>\n",
       "</g>\n",
       "<!-- 2085876522000 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>2085876522000</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"26.25,-254 26.25,-301.5 237,-301.5 237,-254 26.25,-254\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-272.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"99.25,-254 99.25,-301.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.75\" y=\"-284.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"99.25,-277.75 154.25,-277.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.75\" y=\"-260.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"154.25,-254 154.25,-301.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.62\" y=\"-284.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"154.25,-277.75 237,-277.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.62\" y=\"-260.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085853759504&#45;&gt;2085876522000 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>2085853759504-&gt;2085876522000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-338.27C131.62,-330.56 131.62,-321.78 131.62,-313.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-313.41 131.63,-303.41 128.13,-313.41 135.13,-313.41\"/>\n",
       "</g>\n",
       "<!-- 2085876349072 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>2085876349072</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"31.12,-169.5 31.12,-217 232.12,-217 232.12,-169.5 31.12,-169.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-188.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"94.38,-169.5 94.38,-217\"/>\n",
       "<text text-anchor=\"middle\" x=\"121.88\" y=\"-199.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"94.38,-193.25 149.38,-193.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"121.88\" y=\"-175.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"149.38,-169.5 149.38,-217\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.75\" y=\"-199.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"149.38,-193.25 232.12,-193.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.75\" y=\"-175.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2085876522000&#45;&gt;2085876349072 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>2085876522000-&gt;2085876349072</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-253.77C131.62,-246.06 131.62,-237.28 131.62,-228.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-228.91 131.63,-218.91 128.13,-228.91 135.13,-228.91\"/>\n",
       "</g>\n",
       "<!-- 2085876524176 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>2085876524176</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"37.5,-85 37.5,-132.5 225.75,-132.5 225.75,-85 37.5,-85\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-103.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"88,-85 88,-132.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-115.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"88,-108.75 143,-108.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-91.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"143,-85 143,-132.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.38\" y=\"-115.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"143,-108.75 225.75,-108.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.12\" y=\"-91.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 2085876349072&#45;&gt;2085876524176 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>2085876349072-&gt;2085876524176</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-169.27C131.62,-161.56 131.62,-152.78 131.62,-144.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-144.41 131.63,-134.41 128.13,-144.41 135.13,-144.41\"/>\n",
       "</g>\n",
       "<!-- 2085853482640 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>2085853482640</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"33,-0.5 33,-48 230.25,-48 230.25,-0.5 33,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"69.5\" y=\"-19.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"106,-0.5 106,-48\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.5\" y=\"-30.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"106,-24.25 161,-24.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.5\" y=\"-6.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"161,-0.5 161,-48\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.62\" y=\"-30.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 2)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"161,-24.25 230.25,-24.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.62\" y=\"-6.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 2085876524176&#45;&gt;2085853482640 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>2085876524176-&gt;2085853482640</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.62,-84.77C131.62,-77.06 131.62,-68.28 131.62,-59.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.13,-59.91 131.63,-49.91 128.13,-59.91 135.13,-59.91\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(w2v_dnn, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='TB').create(prog=r'C:\\Program Files\\Graphviz\\bin\\dot.exe', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training, Prediction and Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T12:38:25.902981800Z",
     "start_time": "2023-11-30T12:28:37.368821600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "315/315 [==============================] - 60s 179ms/step - loss: 0.3362 - accuracy: 0.8599 - val_loss: 0.3143 - val_accuracy: 0.8669\n",
      "Epoch 2/10\n",
      "315/315 [==============================] - 58s 186ms/step - loss: 0.2873 - accuracy: 0.8811 - val_loss: 0.3089 - val_accuracy: 0.8686\n",
      "Epoch 3/10\n",
      "315/315 [==============================] - 65s 207ms/step - loss: 0.2771 - accuracy: 0.8837 - val_loss: 0.2969 - val_accuracy: 0.8717\n",
      "Epoch 4/10\n",
      "315/315 [==============================] - 62s 195ms/step - loss: 0.2716 - accuracy: 0.8868 - val_loss: 0.2927 - val_accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "315/315 [==============================] - 59s 188ms/step - loss: 0.2672 - accuracy: 0.8868 - val_loss: 0.2944 - val_accuracy: 0.8749\n",
      "Epoch 6/10\n",
      "315/315 [==============================] - 57s 182ms/step - loss: 0.2627 - accuracy: 0.8908 - val_loss: 0.3004 - val_accuracy: 0.8726\n",
      "Epoch 7/10\n",
      "315/315 [==============================] - 58s 184ms/step - loss: 0.2536 - accuracy: 0.8953 - val_loss: 0.2981 - val_accuracy: 0.8703\n",
      "Epoch 8/10\n",
      "315/315 [==============================] - 57s 181ms/step - loss: 0.2521 - accuracy: 0.8945 - val_loss: 0.2962 - val_accuracy: 0.8780\n",
      "Epoch 9/10\n",
      "315/315 [==============================] - 56s 179ms/step - loss: 0.2457 - accuracy: 0.8971 - val_loss: 0.3004 - val_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      "315/315 [==============================] - 56s 177ms/step - loss: 0.2406 - accuracy: 0.8997 - val_loss: 0.3083 - val_accuracy: 0.8757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e5a8a2cfd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "w2v_dnn.fit(avg_wv_train_features, y_train, epochs=10, batch_size=batch_size, \n",
    "            shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T12:51:05.210764900Z",
     "start_time": "2023-11-30T12:50:51.102214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 14s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(w2v_dnn.predict(avg_wv_test_features), axis=1)\n",
    "predictions = le.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T12:51:11.238263600Z",
     "start_time": "2023-11-30T12:51:09.820779300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8812\n",
      "Precision: 0.8819\n",
      "Recall: 0.8812\n",
      "F1 Score: 0.8811\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.87      0.90      0.88      7510\n",
      "    negative       0.90      0.86      0.88      7490\n",
      "\n",
      "    accuracy                           0.88     15000\n",
      "   macro avg       0.88      0.88      0.88     15000\n",
      "weighted avg       0.88      0.88      0.88     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6437     1053\n",
      "        negative        729     6781\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predictions, \n",
    "                                      classes=['positive', 'negative'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T12:54:11.945990200Z",
     "start_time": "2023-11-30T12:54:11.810422400Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_dnn = construct_deepnn_architecture(num_input_features=96)  # angepasst an spaCy Sprachmodell (Vektorlänge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:02:54.207142400Z",
     "start_time": "2023-11-30T12:54:12.728116500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "315/315 [==============================] - 60s 183ms/step - loss: 0.6871 - accuracy: 0.6218 - val_loss: 0.6444 - val_accuracy: 0.6294\n",
      "Epoch 2/10\n",
      "315/315 [==============================] - 51s 162ms/step - loss: 0.6194 - accuracy: 0.6603 - val_loss: 0.6703 - val_accuracy: 0.6171\n",
      "Epoch 3/10\n",
      "315/315 [==============================] - 50s 159ms/step - loss: 0.6026 - accuracy: 0.6759 - val_loss: 0.6089 - val_accuracy: 0.6691\n",
      "Epoch 4/10\n",
      "315/315 [==============================] - 54s 172ms/step - loss: 0.5950 - accuracy: 0.6810 - val_loss: 0.6204 - val_accuracy: 0.6666\n",
      "Epoch 5/10\n",
      "315/315 [==============================] - 53s 168ms/step - loss: 0.5877 - accuracy: 0.6857 - val_loss: 0.6224 - val_accuracy: 0.6543\n",
      "Epoch 6/10\n",
      "315/315 [==============================] - 51s 162ms/step - loss: 0.5832 - accuracy: 0.6905 - val_loss: 0.6181 - val_accuracy: 0.6546\n",
      "Epoch 7/10\n",
      "315/315 [==============================] - 51s 162ms/step - loss: 0.5772 - accuracy: 0.6963 - val_loss: 0.6051 - val_accuracy: 0.6731\n",
      "Epoch 8/10\n",
      "315/315 [==============================] - 50s 158ms/step - loss: 0.5706 - accuracy: 0.7005 - val_loss: 0.6221 - val_accuracy: 0.6603\n",
      "Epoch 9/10\n",
      "315/315 [==============================] - 50s 160ms/step - loss: 0.5644 - accuracy: 0.7077 - val_loss: 0.6150 - val_accuracy: 0.6554\n",
      "Epoch 10/10\n",
      "315/315 [==============================] - 51s 161ms/step - loss: 0.5588 - accuracy: 0.7099 - val_loss: 0.6255 - val_accuracy: 0.6434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e5ad3a9210>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "glove_dnn.fit(train_glove_features, y_train, epochs=10, batch_size=batch_size, \n",
    "              shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:10:26.326507900Z",
     "start_time": "2023-11-30T13:10:14.411687600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 11s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(glove_dnn.predict(test_glove_features), axis=1)\n",
    "predictions = le.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:10:30.299183800Z",
     "start_time": "2023-11-30T13:10:28.758634300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.6579\n",
      "Precision: 0.6779\n",
      "Recall: 0.6579\n",
      "F1 Score: 0.6479\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.62      0.83      0.71      7510\n",
      "    negative       0.74      0.49      0.59      7490\n",
      "\n",
      "    accuracy                           0.66     15000\n",
      "   macro avg       0.68      0.66      0.65     15000\n",
      "weighted avg       0.68      0.66      0.65     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       3663     3827\n",
      "        negative       1304     6206\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predictions, \n",
    "                                      classes=['positive', 'negative'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "schlechtere Werte, wohl auch durch die kleineren Wortvektoren\n",
    "\n",
    "kann sicherlich mit mehr Rechenaufwand und einem umfangreicheren Sprachmodell verbessert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
